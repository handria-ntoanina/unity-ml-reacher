import numpy as np

import torch
import torch.nn as nn
import torch.nn.functional as F
from agents.utils import soft_update

def layer_init(layer, scale=1.0):
    nn.init.orthogonal_(layer.weight.data, scale)
    nn.init.constant_(layer.bias.data, 0)
    return layer

class Gaussian(nn.Module):
    def __init__(self, state_size, action_size, seed):
        super().__init__()
        self.seed = torch.manual_seed(seed)
        self.actor = FullyConnected([state_size, 64, 64, action_size], seed)
        self.critic = FullyConnected([state_size, 64, 64, 1], seed)
        self.critic_target = FullyConnected([state_size, 64, 64, 1], seed)
        soft_update(self.critic, self.critic_target, 1)
        
        # Need to check if this is adjusted during backpropagation or not
        self.std = nn.Parameter(torch.ones(1, action_size))
    
    def forward(self, state, action=None):
        """
            The actor network gets the parameters of the state inputs
            Then generate a settings mu of a gaussian distribution for each type of action with std as standard deviation
            Afterwards, that distribution is sampled, and we get values for the actions
            That allows us to get also the log probability of the sampled values
            
            When an action is provided, the actor network generates the mu from the state inputs
            We can look then for the log probability of the provided action in regards to the distribution generated by the network
        """
        mu = self.actor(state)
        dist = torch.distributions.Normal(mu, self.std)
        if action is None:
            action = dist.sample()
        log_prob = dist.log_prob(action)
        log_prob = log_prob.sum(dim=1, keepdim=True)
        value = self.critic(state)
        return action, log_prob, value        

class FullyConnected(nn.Module):
    def __init__(self, hidden_layers_size, seed):
        """Initialize parameters and build model.
        Params
        ======
            state_size (int): Dimension of each state
            action_size (int): Dimension of action space
            seed (int): Random seed
        """
        super().__init__()
        self.seed = torch.manual_seed(seed)
        self.hidden_layers = nn.ModuleList()
        self.hidden_layers.extend([nn.Linear(hidden_layers_size[i], hidden_layers_size[i + 1]) for i in range(len(hidden_layers_size) - 1)])
        self.reset_parameters()

    def reset_parameters(self):
        for i in range(len(self.hidden_layers)-1):
            layer_init(self.hidden_layers[i])
        
    def forward(self, state):
        """Build a network that maps state to actions."""
        x = state
        for i in range(len(self.hidden_layers)):
            linear = self.hidden_layers[i]
            x = F.relu(linear(x))
        return x
